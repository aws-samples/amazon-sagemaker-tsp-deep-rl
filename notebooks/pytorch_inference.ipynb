{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596674d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black\n",
    "\n",
    "from problems.tsp.problem_tsp import TSP\n",
    "from utils import load_model, move_to\n",
    "from torch.utils.data import DataLoader\n",
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69305934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d752194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcd13bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONLinesSerializer\n",
    "from sagemaker.deserializers import JSONLinesDeserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2148f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sagemaker.Session()\n",
    "BUCKET = session.default_bucket()  # Set a default S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210d7eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set USE_PRETRAINED_MODEL to False if you have trained a model using pytorch_training.ipynb\n",
    "USE_PRETRAINED_MODEL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeddad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL_PATH = \"../learning-tsp/pretrained/tsp_20-50/rl-ar-var-20pnn-gnn-max_20200313T002243/model.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc88639",
   "metadata": {},
   "source": [
    "# 1. Test inference code locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263e7353",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab2de2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = None\n",
    "batch_size = 1\n",
    "accumulation_steps = 80\n",
    "num_samples = 2  # 1280 samples per TSP size\n",
    "\n",
    "neighbors = 0.20\n",
    "knn_strat = \"percentage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c2d289",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TSP.make_dataset(\n",
    "    filename=dataset_path,\n",
    "    batch_size=batch_size,\n",
    "    num_samples=num_samples,\n",
    "    min_size=10,\n",
    "    max_size=10,\n",
    "    neighbors=neighbors,\n",
    "    knn_strat=knn_strat,\n",
    "    supervised=False,\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c575acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data\n",
    "data = []\n",
    "for bat_idx, bat in enumerate(dataloader):\n",
    "    input = {}\n",
    "    input[\"nodes\"] = bat[\"nodes\"].tolist()\n",
    "    data.append(input)\n",
    "for record in data:\n",
    "    record[\"neighbors\"] = neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2032d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f62fbc",
   "metadata": {},
   "source": [
    "## Prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd818d9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting the latest model data from the training jobs\n",
    "def get_latest_model():\n",
    "    client = boto3.client(\"sagemaker\")\n",
    "\n",
    "    # Get the trained sklearn model\n",
    "    response = client.list_training_jobs(\n",
    "        NameContains=\"pytorch-smdataparallel-tsp\",\n",
    "        StatusEquals=\"Completed\",\n",
    "        SortBy=\"CreationTime\",\n",
    "        SortOrder=\"Descending\",\n",
    "    )\n",
    "    training_job_name = response[\"TrainingJobSummaries\"][0][\"TrainingJobName\"]\n",
    "    model_s3 = client.describe_training_job(TrainingJobName=training_job_name)[\n",
    "        \"ModelArtifacts\"\n",
    "    ][\"S3ModelArtifacts\"]\n",
    "    return model_s3\n",
    "\n",
    "\n",
    "# Upload a pretrained model to s3\n",
    "def upload_pretrained_model():\n",
    "    s3 = boto3.resource(\"s3\")\n",
    "    S3_PATH = PRETRAINED_MODEL_PATH.lstrip(\"../\")\n",
    "    s3.meta.client.upload_file(PRETRAINED_MODEL_PATH, BUCKET, S3_PATH)\n",
    "    return f\"s3://{BUCKET}/{S3_PATH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95568be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_PRETRAINED_MODEL == True:\n",
    "    model_data = upload_pretrained_model()\n",
    "else:\n",
    "    model_data = get_latest_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017a98ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3880d20",
   "metadata": {},
   "source": [
    "## Download the model locally for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb696771",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp $model_data ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712a9359",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e3ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvzf ./model.tar.gz -C ./model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c754b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bac442",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbacc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./model\"\n",
    "model = model_fn(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd457e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcecb1b",
   "metadata": {},
   "source": [
    "## Define input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e453ff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "serializer = JSONLinesSerializer()\n",
    "\n",
    "data_jsonlines = serializer.serialize(data)\n",
    "\n",
    "request_body = data_jsonlines.encode(\"utf-8\")\n",
    "\n",
    "input_data = input_fn(request_body)\n",
    "\n",
    "with open(\"inference_input\", \"w\") as file:\n",
    "    file.write(data_jsonlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34796d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to S3 for batch transform\n",
    "!aws s3 cp inference_input s3://$BUCKET/data/inference/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec1e383",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e822966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246624be",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict_fn(input_data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2044dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd697611",
   "metadata": {},
   "source": [
    "## Define output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5404a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output_fn(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fd7d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1678c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prediction\", \"w\") as file:\n",
    "    file.write(output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcf9620",
   "metadata": {},
   "source": [
    "# 2. Test inference code via endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66458965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "model_sm = PyTorchModel(\n",
    "    model_data=model_data,\n",
    "    source_dir=\"../src\",\n",
    "    entry_point=\"inference.py\",\n",
    "    role=role,\n",
    "    framework_version=\"1.8.1\",\n",
    "    py_version=\"py36\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dae6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = model_sm.deploy(initial_instance_count=1,\n",
    "                         instance_type=\"ml.m4.xlarge\",\n",
    "                         serializer=JSONLinesSerializer(),\n",
    "                         deserializer=JSONLinesDeserializer(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f122f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the sampled images to endpoint for inference\n",
    "prediction = predictor.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798156e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c87c118",
   "metadata": {},
   "source": [
    "# 3. Batch Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d8f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = model_sm.transformer(instance_count=1, \n",
    "                     instance_type='ml.m5.2xlarge', \n",
    "                     strategy='MultiRecord',\n",
    "                     assemble_with='Line',\n",
    "                     accept='application/jsonlines',\n",
    "                     max_concurrent_transforms=4,\n",
    "                     env = {'SAGEMAKER_MODEL_SERVER_TIMEOUT' : '3600' },\n",
    "                     #output_path='s3://{}/output'.format(bucket),\n",
    "                     #sagemaker_session=sagemaker_session\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb874227",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.transform(f's3://{BUCKET}/data/inference/inference_input',\n",
    "                      content_type='application/jsonlines',\n",
    "                     split_type='Line',\n",
    "                     wait=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0f6e5a",
   "metadata": {},
   "source": [
    "# 4. Clean up (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abe7820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the SageMaker endpoint\n",
    "predictor.delete_endpoint()\n",
    "\n",
    "# Delete the SageMaker model\n",
    "model_sm.delete_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
